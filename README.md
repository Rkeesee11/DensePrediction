# DensePrediction

# Vision Transformer for Depth Estimation

## Description
This project uses a Vision Transformer (ViT) model for monocular depth estimation. The model is trained on a custom dataset and evaluated on test images.


[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Rkeesee11/DensePrediction/drive/simplified_midas_reproduction.ipynb)



Or paste this link:
https://colab.research.google.com/drive/1CZyRhTxWD-ngnGNtxPyQ0cuWMj0eIdqq?usp=sharing


## Requirements
- Google Colab (recommended) or local environment
- Python 3.x
- PyTorch
- torchvision
- numpy
- matplotlib

## Usage
1. Upload a test image, name it text_image.jpg
2. Run the depth estimation model.
3. Visualize the predicted depth map.

## Results
The model produces a depth map of any image you upload in the correct format of jpg or png!
This is not an improvement from our article, but it does replicate it in a way.
